{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","import numpy as np\n","from torch.optim import Adam\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["\n","# Check if GPU is available and set the device accordingly\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')\n","\n","# Define the CNN model\n","class SentimentCNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n","        super(SentimentCNN, self).__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        self.convs = nn.ModuleList([\n","            nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs, embedding_dim))\n","            for fs in filter_sizes\n","        ])\n","        \n","        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        x = x.long()\n","        embedded = self.embedding(x)\n","        embedded = embedded.unsqueeze(1)\n","        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n","        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n","        cat = self.dropout(torch.cat(pooled, dim=1))\n","        return self.fc(cat)\n","\n","# Dataset class\n","class ReviewsDataset(Dataset):\n","    def __init__(self, reviews, labels):\n","        self.reviews = reviews\n","        self.labels = labels\n","        \n","    def __len__(self):\n","        return len(self.labels)\n","    \n","    def __getitem__(self, idx):\n","        return torch.tensor(self.reviews[idx], dtype=torch.int64), torch.tensor(self.labels[idx], dtype=torch.int64)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","# Tokenization and vectorization\n","def tokenize_and_encode(texts, vocab_size=10000):\n","    tokenized_texts = [text.split() for text in texts]\n","    all_words = [word for text in tokenized_texts for word in text]\n","    most_common_words = [word for word, _ in Counter(all_words).most_common(vocab_size)]\n","    word_to_index = {word: i + 1 for i, word in enumerate(most_common_words)}  # +1 for padding index 0\n","    \n","    encoded_texts = []\n","    for text in tokenized_texts:\n","        encoded_text = [word_to_index.get(word, 0) for word in text]  # Use 0 for unknown words\n","        encoded_texts.append(encoded_text)\n","    \n","    return encoded_texts, word_to_index\n","\n","# Load and preprocess the data\n","df = pd.read_csv('./dataset/Final_CompanyReviews.csv')\n","reviews = df['review_description'].astype(str).fillna(\"\")  # Convert to string and fill NaN\n","labels = df['rating'].values\n","\n","# Tokenize and encode the reviews\n","encoded_reviews, word_to_index = tokenize_and_encode(reviews)\n","max_length = max(len(review) for review in encoded_reviews)\n","padded_reviews = [review + [0] * (max_length - len(review)) for review in encoded_reviews]\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(padded_reviews, labels, test_size=0.2, random_state=42, )\n","\n","# Create Datasets and DataLoaders\n","train_dataset = ReviewsDataset(X_train, y_train)\n","test_dataset = ReviewsDataset(X_test, y_test)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the model...\n","Epoch: 1, Training Loss: 0.6701, Test Loss: 0.5827, Test Accuracy: 0.7735\n","Epoch: 2, Training Loss: 0.5345, Test Loss: 0.5369, Test Accuracy: 0.7989\n","Epoch: 3, Training Loss: 0.4701, Test Loss: 0.5232, Test Accuracy: 0.8105\n","Epoch: 4, Training Loss: 0.4217, Test Loss: 0.5473, Test Accuracy: 0.8087\n","Epoch: 5, Training Loss: 0.3813, Test Loss: 0.5372, Test Accuracy: 0.8120\n","Epoch: 6, Training Loss: 0.3513, Test Loss: 0.5631, Test Accuracy: 0.8157\n","Epoch: 7, Training Loss: 0.3164, Test Loss: 0.5943, Test Accuracy: 0.8170\n","Epoch: 8, Training Loss: 0.2984, Test Loss: 0.6205, Test Accuracy: 0.8149\n","Epoch: 9, Training Loss: 0.2686, Test Loss: 0.6554, Test Accuracy: 0.8137\n","Epoch: 10, Training Loss: 0.2535, Test Loss: 0.6777, Test Accuracy: 0.8099\n","Epoch: 11, Training Loss: 0.2385, Test Loss: 0.7556, Test Accuracy: 0.8181\n","Epoch: 12, Training Loss: 0.2195, Test Loss: 0.7838, Test Accuracy: 0.8147\n","Epoch: 13, Training Loss: 0.2114, Test Loss: 0.8455, Test Accuracy: 0.8155\n","Epoch: 14, Training Loss: 0.2034, Test Loss: 0.8696, Test Accuracy: 0.8129\n","Epoch: 15, Training Loss: 0.1915, Test Loss: 0.8976, Test Accuracy: 0.8089\n","Epoch: 16, Training Loss: 0.1868, Test Loss: 0.9415, Test Accuracy: 0.8096\n","Epoch: 17, Training Loss: 0.1769, Test Loss: 0.9891, Test Accuracy: 0.8085\n","Epoch: 18, Training Loss: 0.1745, Test Loss: 1.0320, Test Accuracy: 0.8104\n","Epoch: 19, Training Loss: 0.1674, Test Loss: 1.0785, Test Accuracy: 0.8096\n","Epoch: 20, Training Loss: 0.1600, Test Loss: 1.1643, Test Accuracy: 0.8014\n","Epoch: 21, Training Loss: 0.1611, Test Loss: 1.2339, Test Accuracy: 0.8106\n","Epoch: 22, Training Loss: 0.1546, Test Loss: 1.2360, Test Accuracy: 0.8101\n","Epoch: 23, Training Loss: 0.1513, Test Loss: 1.3269, Test Accuracy: 0.8114\n","Epoch: 24, Training Loss: 0.1480, Test Loss: 1.3041, Test Accuracy: 0.8052\n","Epoch: 25, Training Loss: 0.1455, Test Loss: 1.4170, Test Accuracy: 0.8105\n","Epoch: 26, Training Loss: 0.1395, Test Loss: 1.4074, Test Accuracy: 0.8020\n","Epoch: 27, Training Loss: 0.1435, Test Loss: 1.4781, Test Accuracy: 0.8065\n","Epoch: 28, Training Loss: 0.1421, Test Loss: 1.5250, Test Accuracy: 0.8065\n","Epoch: 29, Training Loss: 0.1349, Test Loss: 1.5163, Test Accuracy: 0.8007\n","Epoch: 30, Training Loss: 0.1333, Test Loss: 1.6102, Test Accuracy: 0.8057\n","Best test accuracy: 0.8181\n","Training time: 268.8056745529175s\n"]}],"source":["\n","# Model parameters\n","vocab_size = len(word_to_index) + 1  # +1 for padding index\n","embedding_dim = 100\n","n_filters = 100\n","filter_sizes = [3, 4, 5]\n","output_dim = 3  # 3 classes: positive, negative, neutral\n","dropout = 0.5\n","\n","# Instantiate the model and move it to the device\n","model = SentimentCNN(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters())\n","\n","# Training loop\n","def train(model, train_loader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    for texts, labels in train_loader:\n","        texts, labels = texts.to(device), labels.to(device)\n","        predictions = model(texts)\n","        loss = criterion(predictions, labels)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    avg_loss = total_loss / len(train_loader)\n","    return avg_loss\n","\n","# Evaluation function\n","def evaluate(model, data_loader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    correct_predictions = 0\n","    total_predictions = 0\n","\n","    with torch.no_grad():\n","        for texts, labels in data_loader:\n","            texts, labels = texts.to(device), labels.to(device)\n","            predictions = model(texts)\n","            loss = criterion(predictions, labels)\n","            total_loss += loss.item()\n","\n","            _, predicted_labels = torch.max(predictions, 1)\n","            correct_predictions += (predicted_labels == labels).sum().item()\n","            total_predictions += labels.size(0)\n","\n","    avg_loss = total_loss / len(data_loader)\n","    accuracy = correct_predictions / total_predictions\n","    return avg_loss, accuracy\n","\n","# Train and evaluate the model\n","print(\"Training the model...\")\n","init_time = time.time()\n","num_epochs = 30\n","best_accuracy = 0\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, optimizer, criterion, device)\n","    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n","    print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n","    if test_accuracy > best_accuracy:\n","        best_accuracy = test_accuracy\n","        torch.save(model.state_dict(), 'best_model.pt')\n","print(f'Best test accuracy: {best_accuracy:.4f}')\n","print(f\"Training time: {time.time() - init_time}s\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","# Prediction function\n","def predict(model, text, word_to_index, max_length, device):\n","    model.eval()\n","    tokens = text.split()\n","    encoded_text = [word_to_index.get(token, 0) for token in tokens]\n","    padded_text = encoded_text + [0] * (max_length - len(encoded_text))\n","    input_tensor = torch.tensor(padded_text, dtype=torch.int64).unsqueeze(0).to(device)\n","    \n","    with torch.no_grad():\n","        prediction = model(input_tensor)\n","        _, predicted_label = torch.max(prediction, 1)\n","    \n","    return predicted_label.item()\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Review: (الجو حلو والمكان جميل), Predicted Label: 1\n","Review: (المكان سيء والخدمة سيئة), Predicted Label: 0\n","Review: (المكان عادي والخدمة عادية), Predicted Label: 1\n"]}],"source":["list_of_reviews = ['الجو حلو والمكان جميل', 'المكان سيء والخدمة سيئة', 'المكان عادي والخدمة عادية']\n","for review in list_of_reviews:\n","    label = predict(model, review, word_to_index, max_length, device)\n","    print(f'Review: ({review}), Predicted Label: {label}')\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading the best model...\n","Review: (الجو حلو والمكان جميل), Predicted Label: 1\n","Review: (المكان سيء والخدمة سيئة), Predicted Label: 0\n","Review: (المكان عادي والخدمة عادية), Predicted Label: 1\n"]}],"source":["print(\"Loading the best model...\")\n","model.load_state_dict(torch.load('best_model.pt'))\n","model.to(device)\n","for review in list_of_reviews:\n","    label = predict(model, review, word_to_index, max_length, device)\n","    print(f'Review: ({review}), Predicted Label: {label}')"]}],"metadata":{"kernelspec":{"display_name":"PyTorch_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
